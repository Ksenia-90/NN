{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dz_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPy6FZmyB+8GqE8p0WqqgQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ksenia-90/NN/blob/lesson_8/dz_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Урок 8. GAN"
      ],
      "metadata": {
        "id": "B5GX_3WkJFwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добрый день! Дополнила раздор статьи из 7 задания (и отнесла ее и к 8 уроку в более расширенном разборе)"
      ],
      "metadata": {
        "id": "dNcZ8pzp6M03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud: https://openaccess.thecvf.com/content_CVPR_2020/papers/Shi_Point-GNN_Graph_Neural_Network_for_3D_Object_Detection_in_a_CVPR_2020_paper.pdf\n",
        "\n",
        "В данной статье описывается 3D моделирование. В статье эксперты утверждают, что контрольные показатели показывают, что предлагаемый подход достигает лидирующих точность с использованием только облака точек и может даже превзойти алгоритмы на основе слияния, демонстрируют потенциал использования графовой нейронной сети как нового подхода к обнаружению 3D-объектов. Loss oписан в пункте 3.3 Oперация свертки эффективна, но для нее требуется регулярная сетка, В отличие от изображения, облако точек обычно является разреженным и неравномерно распределены по регулярной сетке. Учеными, в статье, предполается что данная сеть будет использоваться для высокоточного обнаружения обьектов. В слое подачи данных самая большая проблема - подаётся граф на основании данных лидара. Point-GNN принимает точечный график в качестве входных данных. Выводит категорию и ограничивающие рамки объектов, которым принадлежит каждая вершина. В статье дается ссылка на код: https://github.com/WeijingShi/Point-GNN. В тесте KITTI Point-GNN достигает высочайшая точность с использованием только облака точек и даже превосходит подходы слияния датчиков. Точка-GNN демонстрирует потенциал подхода к обнаружению 3D-объектов нового типа с использованием графовой нейронной сети, и он может служить в качестве хорошая база для будущих исследований. Проводитлись обширные абляционные исследование эффективности компонентов Point-GNN. В этой статье: • Мы предлагаем новый подход к обнаружению объектов с использованием граф нейронной сети на облаке точек. • Мы разрабатываем Point-GNN, графовую нейронную сеть с механизм автоматической регистрации, который обнаруживает несколько объектов в одном кадре. • Мы достигаем высочайшей точности обнаружения 3D-объектов в тесте KITTI и тщательно анализируем эффективность каждого компонента.\n",
        "* общая архитектура  метода состоит из трех компонентов: построение графа, (GNN из T итераций, и  слияние ограничивающих рамок и подсчет очков.\n",
        "Построением такого графа является задача поиска ближайших соседей по радиусу. \n",
        "После построения графа обрабатывается граф с помощью GNN.\n",
        "Типичная графовая нейронная сеть уточняет функции вершин, агрегируя функции вдоль ребер. Если вершина находится внутри ограничивающей рамки объекта, мы присваиваем вершине класс объекта.\n",
        "несколько вершин могут находиться на одном и том же объекте, нейронная сеть может выводить несколько ограничивающих прямоугольников одного и того же объекта.\n",
        "объект. Необходимо объединить эти ограничивающие рамки в\n",
        "один, а также присвоить показатель достоверностию\n",
        "Набор данных KITTI содержит 7481 обучающая выборка и 7518 тестовых выборок. Каждый образец содержит как облако точек, так и изображение с камеры.\n",
        "Необходимо удаление шума.\n",
        "Используя графовое представление, можно\n",
        "компактно закодировать облако точек без сопоставления с\n",
        "сетки или выборки и группировки неоднократно. Предлагаемый механизм автоматической регистрации снижает дисперсию перехода, а слияние блоков и подсчет очков операция повышает точность обнаружения. "
      ],
      "metadata": {
        "id": "4mB8MfbONuKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D_lH8Xz3Num-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "0Ifu_t3J5Q-x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odL8ZBogOyEV",
        "outputId": "ed1e3b48-8aae-46b4-d658-22fe07dcdb32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qcNQEYb-_5t",
        "outputId": "5879d66f-abb9-41f8-8d0b-715bcf7d8648"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/My Drive/Colab Notebooks/drakula_2.txt').read()"
      ],
      "metadata": {
        "id": "5HFt0uN57Hng"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(input):\n",
        "    input = input.lower()\n",
        "\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input)\n",
        "\n",
        "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)"
      ],
      "metadata": {
        "id": "nEHCTCbWN0SY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_inputs = tokenize_words(file)"
      ],
      "metadata": {
        "id": "uikPQLNDN3XO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "czRmXH7mO_YW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print (\"Total number of characters:\", input_len)\n",
        "print (\"Total vocab:\", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6snCxAlJPD-z",
        "outputId": "3dfa3457-3866-40b4-cab3-bae61e4b8be9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 31345\n",
            "Total vocab: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "6tT_5YYQPIgq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, input_len - seq_length, 1):\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])\n"
      ],
      "metadata": {
        "id": "ESWcv4WlPTH0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IghG7MkPaEB",
        "outputId": "e70d8b51-7934-4183-e068-0f30dc303bc5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 31245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "nvf993JLPeTw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np_utils.to_categorical(y_data)"
      ],
      "metadata": {
        "id": "C8n4_dNjPkVx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n"
      ],
      "metadata": {
        "id": "0fC5_NTdPpq4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n"
      ],
      "metadata": {
        "id": "bKM9Udn1Pw9V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdunfV14P-Pe",
        "outputId": "f12289a9-1f5d-45b4-f93d-67eb71953c17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "123/123 [==============================] - 426s 3s/step - loss: 2.9740\n",
            "Epoch 2/50\n",
            "123/123 [==============================] - 431s 4s/step - loss: 2.9176\n",
            "Epoch 3/50\n",
            "123/123 [==============================] - 437s 4s/step - loss: 2.7999\n",
            "Epoch 4/50\n",
            "123/123 [==============================] - 419s 3s/step - loss: 2.6705\n",
            "Epoch 5/50\n",
            "123/123 [==============================] - 417s 3s/step - loss: 2.6236\n",
            "Epoch 6/50\n",
            "123/123 [==============================] - 418s 3s/step - loss: 2.5852\n",
            "Epoch 7/50\n",
            "123/123 [==============================] - 418s 3s/step - loss: 2.5493\n",
            "Epoch 8/50\n",
            "123/123 [==============================] - 421s 3s/step - loss: 2.5172\n",
            "Epoch 9/50\n",
            "123/123 [==============================] - 421s 3s/step - loss: 2.4849\n",
            "Epoch 10/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 2.4537\n",
            "Epoch 11/50\n",
            "123/123 [==============================] - 423s 3s/step - loss: 2.4256\n",
            "Epoch 12/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 2.3957\n",
            "Epoch 13/50\n",
            "123/123 [==============================] - 426s 3s/step - loss: 2.3674\n",
            "Epoch 14/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 2.3404\n",
            "Epoch 15/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 2.3133\n",
            "Epoch 16/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 2.2880\n",
            "Epoch 17/50\n",
            "123/123 [==============================] - 430s 3s/step - loss: 2.2632\n",
            "Epoch 18/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 2.2390\n",
            "Epoch 19/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 2.2147\n",
            "Epoch 20/50\n",
            "123/123 [==============================] - 425s 3s/step - loss: 2.1883\n",
            "Epoch 21/50\n",
            "123/123 [==============================] - 425s 3s/step - loss: 2.1642\n",
            "Epoch 22/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 2.1488\n",
            "Epoch 23/50\n",
            "123/123 [==============================] - 430s 3s/step - loss: 2.1221\n",
            "Epoch 24/50\n",
            "123/123 [==============================] - 430s 3s/step - loss: 2.1009\n",
            "Epoch 25/50\n",
            "123/123 [==============================] - 436s 4s/step - loss: 2.0791\n",
            "Epoch 26/50\n",
            "123/123 [==============================] - 432s 4s/step - loss: 2.0559\n",
            "Epoch 27/50\n",
            "123/123 [==============================] - 429s 3s/step - loss: 2.0398\n",
            "Epoch 28/50\n",
            "123/123 [==============================] - 428s 3s/step - loss: 2.0226\n",
            "Epoch 29/50\n",
            "123/123 [==============================] - 431s 4s/step - loss: 2.0011\n",
            "Epoch 30/50\n",
            "123/123 [==============================] - 436s 4s/step - loss: 1.9763\n",
            "Epoch 31/50\n",
            "123/123 [==============================] - 436s 4s/step - loss: 1.9600\n",
            "Epoch 32/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 1.9413\n",
            "Epoch 33/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 1.9196\n",
            "Epoch 34/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 1.9002\n",
            "Epoch 35/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 1.8826\n",
            "Epoch 36/50\n",
            "123/123 [==============================] - 425s 3s/step - loss: 1.8600\n",
            "Epoch 37/50\n",
            "123/123 [==============================] - 426s 3s/step - loss: 1.8342\n",
            "Epoch 38/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 1.8215\n",
            "Epoch 39/50\n",
            "123/123 [==============================] - 425s 3s/step - loss: 1.8065\n",
            "Epoch 40/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 1.7810\n",
            "Epoch 41/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 1.7996\n",
            "Epoch 42/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 1.8175\n",
            "Epoch 43/50\n",
            "123/123 [==============================] - 428s 3s/step - loss: 1.8364\n",
            "Epoch 44/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 1.7892\n",
            "Epoch 45/50\n",
            "123/123 [==============================] - 427s 3s/step - loss: 1.7809\n",
            "Epoch 46/50\n",
            "123/123 [==============================] - 422s 3s/step - loss: 1.8963\n",
            "Epoch 47/50\n",
            "123/123 [==============================] - 421s 3s/step - loss: 2.0315\n",
            "Epoch 48/50\n",
            "123/123 [==============================] - 423s 3s/step - loss: 1.7657\n",
            "Epoch 49/50\n",
            "123/123 [==============================] - 423s 3s/step - loss: 1.7676\n",
            "Epoch 50/50\n",
            "123/123 [==============================] - 424s 3s/step - loss: 1.7514\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62dcc7d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "z84xvJUkQSbH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = np.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14-n2kdFQV4l",
        "outputId": "49034d22-50a4-47af-da6d-10e157eebcc0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" find home dawn struggling windows felt morning day overwork flesh answered pinching test eyes deceiv \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "\n",
        "    sys.stdout.write(result)\n",
        "\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hJwFgwLQaMP",
        "outputId": "76e3898b-2228-4134-9266-d064b8147e60"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ed sall tent exen tindow see wind coule see shall said thin thndo lan taid shall tert pertens begind said taid taid taid thie went dear _bc whie went asay hoow sodt shil soom lonki lan said sha man lieht pat sare shall teen sent koonin thie woued shall ready sime shall tall thndo loneon seall tiies teneome hous windo ligh gate shough wind shall rtran hand shoug light strne tiie shough went soon little wiodow seeth shose shough whnse shoe fare tould soust exer eren whndow sould said soom looki lany said couet window sould said soom look dount ray sinugh shou shou hear seeth sent bed gear _oye sid soom lonki lan aartle went sent sent sent exer sindow seeth shose shou hear sout side coule couet went sent shen went rent eeas siies ploe larter sime larked could see shall nany tent eoead said thing said could see seen could see shall nany tineow bount eroan wiete sould sime shoug shoug shos hear shing sould sime wineow bea sti shou aske might strang hand tould said said thing said coacula se"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно еще поэксперементировать с показателями. очень много раз не запускала, очень очень долго считается."
      ],
      "metadata": {
        "id": "O4cPce7tG-pe"
      }
    }
  ]
}